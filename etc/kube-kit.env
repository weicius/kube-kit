#!/usr/bin/env bash
# vim: nu:noai:ts=4
# shellcheck shell=bash disable=SC2034

#################### Kubernetes Configurations #######################
# kubernetes-server-linux-amd64.tar.gz file's official download URL:
# https://dl.k8s.io
# https://storage.googleapis.com/kubernetes-release/release
######################################################################
KUBE_DOWNLOAD_URL="https://dl.k8s.io"
# https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG.md
KUBE_VERSION="v1.15.5"
# KUBE_MASTER_VIP is the only exposed ip address, via which
# clients can access kube-apiserver and other services.
# NOTE:
# 1. this ip must be in the same subnet with kubernetes cluster.
# 2. leave it empty if there is only one master.
KUBE_MASTER_VIP="192.168.10.10"
# tips: you can use a simple ipv4 range 'ip1-ip2' to specify
# all the ipv4 addresses in the range [ip1, ip2]
# (ipv4 address is treated as a 32-bit integer)
# e.g. "1.1.1.1-1.1.1.3" equals to "1.1.1.1,1.1.1.2,1.1.1.3"
# formats: comma-separated ipv4 addresses and ipv4 addresses
# range. a.k.a. ip1-ip2,ip3,ip4,ip5-ip6,ip7,ip8
KUBE_MASTER_IPS="192.168.10.11-192.168.10.13"
KUBE_NODE_IPS="192.168.10.11-192.168.10.13"

KUBE_PODS_SUBNET="172.17.0.0/16"
KUBE_SERVICES_SUBNET="10.20.0.0/16"
KUBE_KUBERNETES_SVC_IP="10.20.0.1"
KUBE_DNS_SVC_IP="10.20.0.2"
KUBE_DNS_DOMAIN="k8s.cluster"

# expose kubernetes services via a VIP
# in another subnet of the k8s cluster
KUBE_EXTERNAL_VIP=""
KUBE_EXTERNAL_IFNAME=""

KUBE_LOGS_DIR="/var/log/kubernetes"
KUBE_LOGS_LEVEL="4"
KUBE_CONFIG_DIR="/etc/kubernetes"
KUBE_PKI_DIR="${KUBE_CONFIG_DIR}/pki"

KUBELET_WORKDIR="/var/lib/kubelet"
KUBE_PROXY_MODE="ipvs"

KUBE_ALLOW_PRIVILEGED="true"
KUBE_CLUSTER_NAME="kubernetes"
KUBE_ETCD_PREFIX="/kubernetes"
KUBE_EVENT_TTL="240h"

KUBE_PKI_COUNTRY="CN"
KUBE_PKI_STATE="Beijing"
KUBE_PKI_LOCALITY="Beijing"
KUBE_PKI_EXPIRY="87600h"
KUBE_PKI_KEY_BITS="4096"

KUBE_MASTER_HOSTNAME_PREFIX="k8s-master"
KUBE_NODE_HOSTNAME_PREFIX="k8s-node"

######################################################################
# *********************** Etcd Configurations ************************
######################################################################

ETCD_VERSION="3.3.11"
ETCD_CLUSTER_NAME="k8s-etcd-cluster"
ETCD_CLUSTER_MEMBER_PREFIX="etcd"
ETCD_CONFIG_DIR="/etc/etcd"
ETCD_PKI_DIR="${ETCD_CONFIG_DIR}/pki"
ETCD_WORKDIR="/var/lib/etcd"

######################################################################
# *********************** Docker Configurations **********************
######################################################################

DOCKER_VERSION="19.03.2"
DOCKER_DAEMON_PORT="3486"
# https://segmentfault.com/a/1190000019115546
DOCKER_HUB_MIRROR="https://reg-mirror.qiniu.com"
DOCKER_REPO_MIRROR="https://mirrors.aliyun.com"
# choose one of devicemapper, overlay, overlay2
DOCKER_STORAGE_DRIVER="overlay2"
DOCKER_WORKDIR="/var/lib/docker"
DOCKER_NVIDIA_VERSION="v2"

######################################################################
# ********************** Harbor Configurations ***********************
######################################################################

HARBOR_VERSION="v1.5.4"
HARBOR_ADMIN_PASSWORD="Ro0tme"
HARBOR_MYSQL_ROOT_PASSWORD="R0otme"

######################################################################
# ************** Master Disks Partition Configurations ***************
######################################################################

# each mater need a standalone device to be partitioned into 1 PV, 1 VG and 3 LVs
# to mount separately on /var/lib/docker, /var/lib/etcd and /var/log/kubernetes
ENABLE_MASTER_STANDALONE_DEVICE="true"
KUBE_MASTER_STANDALONE_VG="k8s"
KUBE_MASTER_DOCKER_LV="docker"
KUBE_MASTER_DOCKER_LV_RATIO="0.7"
KUBE_ETCD_LV="etcd"
KUBE_ETCD_LV_RATIO="0.1"
KUBE_MASTER_LOG_LV="logs"
KUBE_MASTER_LOG_LV_RATIO="0.1"

# kube-kit will remove the existed lvs, vgs, pvs in the device before using it.
# and whether to wipe the device completely or not? true/false.
# it will take a very long time if set be 'true', but recommended.
# if the device is a new disk without any filesystem in it, set it to be false.
KUBE_WIPE_DEVICE_COMPLETELY="false"
# the method to wipe the whole device completely: dd or shred
KUBE_WIPE_DEVICE_METHOD="dd"
# how many iterations to wipe the device when using shred?
KUBE_SHRED_ITERATIONS="2"

######################################################################
# *************** Node Disks Partition Configurations ****************
######################################################################

# each node need a standalone device to be partitioned into 1 PV, 1 VG and 3 LVs
# to mount separately on /var/lib/docker, /var/lib/kubelet and /var/log/kubernetes
ENABLE_NODE_STANDALONE_DEVICE="true"
KUBE_NODE_STANDALONE_VG="k8s"
KUBE_NODE_DOCKER_LV="docker"
KUBE_NODE_DOCKER_LV_RATIO="0.7"
KUBE_KUBELET_LV="kubelet"
KUBE_KUBELET_LV_RATIO="0.1"
KUBE_NODE_LOG_LV="logs"
KUBE_NODE_LOG_LV_RATIO="0.1"

######################################################################
# ***************** Calico and Flannel Configurations ****************
######################################################################

ENABLE_CNI_PLUGIN="true"
CNI_VERSION="v0.8.2"
CNI_PLUGIN_TYPE="calico"
CNI_BIN_DIR="/opt/cni/bin"
CNI_CONF_DIR="/etc/cni/net.d"
CNI_DOWNLOAD_URL="https://github.com/containernetworking/plugins/releases/download"

# if all servers have more than one network interface, you can config
# calico (container network) to use a specific subnet to communicate
# with each other by setting the gateway of this network.
# NOTE: this should always be the gateway of the specific subnet.
CALICO_NETWORK_GATEWAY="192.168.20.2"
# supported modes: ipip, bgp
CALICO_MODE="ipip"

FLANNEL_ETCD_PREFIX="/sensetime.com/network"
FLANNEL_VERSION="v0.11.0"
FLANNEL_DOWNLOAD_URL="https://github.com/coreos/flannel/releases/download"
# ref: https://github.com/coreos/flannel/blob/master/Documentation/backends.md
# supported types: vxlan, host-gw, udp
FLANNEL_TYPE="vxlan"

# if all servers have more than one network interface, you can config
# flannel (container network) to use a specific subnet to communicate
# with each other by setting the gateway of this network.
# NOTE: this should always be the gateway of the specific subnet.
FLANNEL_NETWORK_GATEWAY="192.168.20.2"

######################################################################
# **************** Glusterfs and Heketi Configurations ***************
######################################################################

ENABLE_GLUSTERFS="true"
GLUSTERFS_NODE_NAME_PREFIX="glusterfs-node"

# if all servers have more than one network interface, you can config
# glusterfs (storage network) to use a specific subnet to communicate
# with each other by setting the gateway of this network.
# NOTE: this should always be the gateway of the specific subnet.
GLUSTERFS_NETWORK_GATEWAY="192.168.30.2"

######################################################################
# ****************** Local Yum Repos Configurations ******************
######################################################################

# use local repos or not? true/false.
ENABLE_LOCAL_YUM_REPO="true"
# the offline rpms are downloaded from CentOS-${CENTOS_VERSION}
CENTOS_VERSION="7.7.1908"
# LOCAL_YUM_REPO_HOST MUST be in the same subnet with kubernetes cluster.
# Leave it empty to use the first master by default.
LOCAL_YUM_REPO_HOST=""
# httpd should listen one of the ports listed below:
# semanage port -l | grep '^http_port_t'
LOCAL_YUM_REPO_PORT="8008"
LOCAL_YUM_REPO_NAME="kubernetes"

######################################################################
# ******************** NTP Service Configurations ********************
######################################################################

# use local ntp server or not? true/false.
ENABLE_LOCAL_NTP_SERVER="true"
# LOCAL_NTP_SERVER MUST be in the kubernetes cluster.
# Leave it empty to use the first master by default.
LOCAL_NTP_SERVER=""
KUBE_TIMEZONE="Asia/Shanghai"
# sync time every ? hours
KUBE_SYNC_TIME_INTERVAL="4"
# used when 'ENABLE_LOCAL_NTP_SERVER' is false
REMOTE_NTP_SERVER="pool.ntp.org"
# the logfile to record the sync-time events
KUBE_SYNC_TIME_LOG="/var/log/sync-time.log"

######################################################################
# *********************** Other Configurations ***********************
######################################################################

# the version of cfssl.
CFSSL_VERSION="1.3.2"
CFSSL_DOWNLOAD_URL="https://shares-1253284766.cos.ap-beijing.myqcloud.com/cfssl"

# the port of sshd service.
SSHD_PORT="22"
# the bits of rsa keys
SSH_RSA_KEY_BITS="4096"

# the timeout (seconds) of the functions: {ssh,scp}::execute{,_parallel}
SSH_EXECUTE_TIMEOUT="600"
# at most how many seconds will kube-kit wait until something happens?
SECONDS_TO_WAIT="600"

# ignore all the actions which need user's confirm? true/false.
ENABLE_FORCE_MODE="true"
# display the logs without colored text if ENABLE_RAW_LOGS is true.
ENABLE_RAW_LOGS="false"
# check environments before actual deploy actions by force?
ENABLE_FORCE_TO_CHECK_ENV="false"

# how many times will kube-kit clean environments?
KUBE_CLEAN_TIMES="2"

# avoid same job executed multiple times at the same time.
CRONTAB_LOCK_FILE="/var/run/kube-crontab.lock"
# record the outputs of each crontab job.
CRONTAB_LOGS_FILE="/var/log/kube-crontab.log"

# the directory to restore the logs of kube-kit command output.
KUBE_KIT_LOGS_DIR="/var/log/kube-kit"
# record all the environment variables passed to remote servers.
KUBE_KIT_ENV_FILE="/root/.kube-kit.env"
# record the successfully-executed options of kube-kit command itself.
KUBE_KIT_INDICATE_FILE="/root/.kube-kit"
